{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "import csv\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# generate classification report using predictions for categorical model\n",
    "from sklearn.metrics import classification_report, accuracy_score , f1_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling of the splitted reviews\n",
    "The splitted reviews have been labelled using the rule based approach. The keywords for each topics are defined and use to lebel the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0: delivery, 1: service, 2:price, 3: product quality\n",
    "#Each topics and their respective keywords\n",
    "delivery = ['delivery', 'condition', 'package', 'pack', 'fast', 'slow', 'ship', 'bubble', 'wrap', 'envelope', 'slow','parcel','delivered','arrive','courier','bubblewrap','damage','early','earlier','earlier','receive']\n",
    "\n",
    "service = ['reply', 'message', 'service', 'response', 'chat', 'responsive', 'irresponsible', 'unethical', 'contact', 'enquiry', 'unresponsive','friendly','resolve','respond','query']\n",
    "\n",
    "price = ['price', 'sale', 'cheap', 'worth', 'deal', 'flash', 'gift', 'freebie', 'promotion', 'expensive', 'affordable','discount','free','cheaper','promo','value','offer','money','voucher','pricey']\n",
    "\n",
    "quality = ['expiry','manufacture','smell', 'smooth', 'sticky','hydrate','effective','last','lasting','apply','application','colour','color','easy','oily','coverage','sensitive','texture','soft',\n",
    "           'frizzy','quality','dry','effect','oil','skin', 'love','like','satisfied','feel','felt','pores','tight','mask','authentic','expiring','lighten','shade','bright','mascara','lash','waterproof',\n",
    "           'lightweight','foundation','suitable','exp','shelf','manufacture','nice','recommend','result','meg','oskinriginal','again','fake','pigment','scent','dryness','stain','smudge','lip','lipstick','pretty',\n",
    "           'fragrance','promising','hair','repeat','happy','made','moisture','remove','volume','suit','awesome','hope','great','content','clean','work','cute','fit','fantastic','genuine','powder','hard',\n",
    "           'real','eyeliner','gently','makeup','amazing','improvement','allergic','foam','cleanse','best','rubbing','rub','wonderful','water','stay','wear','transfer','wearing','disappoint','crease','cover','conceal',\n",
    "          'concealer','reapply','useful','old','picture','test','crack','soft']\n",
    "\n",
    "no_topic = ['no comments review is an image', 'no review receive', 'your review has been hidden due to inappropriate content note hope may remove the coins awarded for this review']\n",
    "no_topic_words = ['try','thank','tried', 'describe','hope']\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#Stemming of the keywords for each topic\n",
    "delivery_stem = [stemmer.stem(w) for w in delivery]\n",
    "service_stem = [stemmer.stem(w) for w in service]\n",
    "price_stem = [stemmer.stem(w) for w in price]\n",
    "quality_stem = [stemmer.stem(w) for w in quality]\n",
    "no_topic_stem = [stemmer.stem(w) for w in no_topic_words]\n",
    "\n",
    "\n",
    "data_file = 'data/all_data_clean_split.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "df\n",
    "\n",
    "review_list =df.Review_splitted.tolist()\n",
    "\n",
    "review_label = []\n",
    "topic_num = []\n",
    "topic_name = []\n",
    "\n",
    "#Labelling of the splitted reviews based on the keywords\n",
    "for i in range(len(review_list)):\n",
    "    review_raw = review_list[i]\n",
    "    if review_raw in no_topic:\n",
    "        review_label.append(review_raw)\n",
    "        topic_num.append(4)\n",
    "        topic_name.append('no_topic')\n",
    "    else:\n",
    "        review = nltk.word_tokenize(review_list[i])\n",
    "        review_stemmed = [stemmer.stem(w) for w in review]\n",
    "        delivery_count = 0\n",
    "        service_count = 0\n",
    "        price_count = 0\n",
    "        quality_count = 0\n",
    "        no_topic_count = 0\n",
    "        for word in review_stemmed:\n",
    "            if word in delivery_stem:\n",
    "                delivery_count += 1\n",
    "            elif word in service_stem:\n",
    "                service_count += 1\n",
    "            elif word in price_stem:\n",
    "                price_count += 1\n",
    "            elif word in quality_stem:\n",
    "                quality_count += 1\n",
    "            elif word in no_topic_stem:\n",
    "                no_topic_count += 1\n",
    "                \n",
    "        #Label is only given to straighforward reviews that only contains 1 topic. This is to ensure that the classifier\n",
    "        # is able to learn the classification more accurately\n",
    "        if delivery_count > 0 and service_count == 0 and price_count == 0 and quality_count == 0 and no_topic_count == 0:\n",
    "\n",
    "            review_label.append(review_list[i])\n",
    "            topic_num.append(0)\n",
    "            topic_name.append('delivery')\n",
    "        elif delivery_count == 0 and service_count > 0 and price_count == 0 and quality_count == 0 and no_topic_count == 0:\n",
    "            review_label.append(review_list[i])\n",
    "            topic_num.append(1)\n",
    "            topic_name.append('service')\n",
    "        elif delivery_count == 0 and service_count == 0 and price_count > 0 and quality_count == 0 and no_topic_count == 0:\n",
    "            review_label.append(review_list[i])\n",
    "            topic_num.append(2)\n",
    "            topic_name.append('price')\n",
    "        elif delivery_count == 0 and service_count == 0 and price_count == 0 and quality_count > 0 and no_topic_count == 0:\n",
    "            review_label.append(review_list[i])\n",
    "            topic_num.append(3)\n",
    "            topic_name.append('quality')\n",
    "        elif delivery_count == 0 and service_count == 0 and price_count == 0 and quality_count == 0 and no_topic_count > 0:\n",
    "            review_label.append(review_list[i])\n",
    "            topic_num.append(4)\n",
    "            topic_name.append('no_topic')\n",
    "            \n",
    "df_with_label = pd.DataFrame({'review': review_label, 'topic_num': topic_num, 'topic_name':topic_name})\n",
    "# df_with_label.head()\n",
    "# with_label.to_csv('Data/with_label_v2.csv')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of classification model for the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import similarities\n",
    "from gensim import models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        3\n",
      "1        3\n",
      "2        0\n",
      "3        0\n",
      "4        3\n",
      "5        3\n",
      "6        4\n",
      "7        3\n",
      "8        0\n",
      "9        2\n",
      "10       3\n",
      "11       0\n",
      "12       0\n",
      "13       2\n",
      "14       3\n",
      "15       2\n",
      "16       4\n",
      "17       3\n",
      "18       0\n",
      "19       0\n",
      "20       0\n",
      "21       3\n",
      "22       3\n",
      "23       0\n",
      "24       4\n",
      "25       3\n",
      "26       2\n",
      "27       2\n",
      "28       4\n",
      "29       0\n",
      "        ..\n",
      "23819    3\n",
      "23820    0\n",
      "23821    4\n",
      "23822    4\n",
      "23823    4\n",
      "23824    4\n",
      "23825    4\n",
      "23826    3\n",
      "23827    3\n",
      "23828    1\n",
      "23829    0\n",
      "23830    4\n",
      "23831    4\n",
      "23832    4\n",
      "23833    4\n",
      "23834    4\n",
      "23835    4\n",
      "23836    4\n",
      "23837    3\n",
      "23838    3\n",
      "23839    0\n",
      "23840    3\n",
      "23841    4\n",
      "23842    4\n",
      "23843    4\n",
      "23844    4\n",
      "23845    4\n",
      "23846    4\n",
      "23847    4\n",
      "23848    4\n",
      "Name: topic_num, Length: 23849, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "reviews = df_with_label['review']\n",
    "\n",
    "review_docs = []\n",
    "for each_reviews in reviews:\n",
    "    temp = each_reviews.split(\" \")\n",
    "    review_docs.append(temp)\n",
    "# print (review_docs)\n",
    "\n",
    "# Make sure all words are in lowercase\n",
    "reviews_lower = [[each_word.lower() for each_word in each_review] for each_review in review_docs]\n",
    "# print (reviews_lower)\n",
    "\n",
    "# Use regular expressions to keep only allphabetical words\n",
    "reviews_alpha = [[each_word for each_word in each_review if re.search('^[a-z]+$', each_word)] for each_review in reviews_lower]\n",
    "# print (reviews_alpha)\n",
    "\n",
    "# Remove stop words\n",
    "stop_list = stopwords.words('english')\n",
    "reviews_stop = [[each_word for each_word in each_review if each_word not in stop_list] for each_review in reviews_alpha]\n",
    "# print (reviews_stop)\n",
    "\n",
    "# Porter Stemming\n",
    "stemmer = PorterStemmer()\n",
    "reviews_stem = [[stemmer.stem(each_word) for each_word in each_review] for each_review in reviews_stop]\n",
    "# print (reviews_stem)\n",
    "\n",
    "all_data_cleaned = []\n",
    "for each_sentence in reviews_stem:\n",
    "    sentence = \"\"\n",
    "    for each_word in each_sentence:\n",
    "        sentence += each_word + \" \"\n",
    "    sentence = sentence[0:-1]\n",
    "    all_data_cleaned.append(sentence)\n",
    "# print (all_data_cleaned)\n",
    "\n",
    "topic_num = data['topic_num']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model - Multinomial Naive Bayes \n",
    "1. Count Vectorizer\n",
    "2. TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Count Vectorizer\n",
      "F1-score of Multinomial Naive Bayes:  92.55332206254671\n",
      "Accuracy of Multinomial Naive Bayes:  92.67147409022304\n",
      "\n",
      "2. TFIDF Vectorizer\n",
      "F1-score of Multinomial Naive Bayes with TFIDF:  92.8543552552533\n",
      "Accuracy of Multinomial Naive Bayes with TFIDF:  92.93979540499748\n"
     ]
    }
   ],
   "source": [
    "print (\"1. Count Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "topic_num = data['topic_num']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, topic_num, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "mnbClf = MultinomialNB()\n",
    "mnbClf.fit(X_train, y_train)\n",
    "mnbClf_ypred = mnbClf.predict(X_test)\n",
    "f1_mnbClf = f1_score(y_test, mnbClf_ypred, average = 'weighted')\n",
    "accuracy_mnbClf = accuracy_score(y_test, mnbClf_ypred)\n",
    "print (\"F1-score of Multinomial Naive Bayes: \", f1_mnbClf*100)\n",
    "print (\"Accuracy of Multinomial Naive Bayes: \", accuracy_mnbClf*100)\n",
    "\n",
    "print (\"\\n2. TFIDF Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "topic_num = data['topic_num']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, topic_num, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "mnbTfidfClf = MultinomialNB()\n",
    "mnbTfidfClf.fit(X_train, y_train)\n",
    "mnbTfidfClf_ypred = mnbTfidfClf.predict(X_test)\n",
    "f1_mnbTfidfClf = f1_score(y_test, mnbTfidfClf_ypred, average='weighted')\n",
    "accuracy_mnbTfidfClf = accuracy_score(y_test, mnbTfidfClf_ypred)\n",
    "print (\"F1-score of Multinomial Naive Bayes with TFIDF: \", f1_mnbTfidfClf*100)\n",
    "print (\"Accuracy of Multinomial Naive Bayes with TFIDF: \", accuracy_mnbTfidfClf*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model - Bernoulli Naive Bayes\n",
    "1. Count Vectorizer\n",
    "2. TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Count Vectorizer\n",
      "F1-score of Bernoulli Naive Bayes:  90.91530178040284\n",
      "Accuracy of Bernoulli Naive Bayes:  91.0950863659232\n",
      "\n",
      "2. TFIDF Vectorizer\n",
      "F1-score of Bernoulli Naive Bayes with TFIDF:  90.91530178040284\n",
      "Accuracy of Bernoulli Naive Bayes with TFIDF:  91.0950863659232\n"
     ]
    }
   ],
   "source": [
    "print (\"1. Count Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "topic_num = data['topic_num']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, topic_num, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "bnbClf = BernoulliNB()\n",
    "bnbClf.fit(X_train, y_train)\n",
    "bnbClf_ypred = bnbClf.predict(X_test)\n",
    "f1_bnbClf = f1_score(y_test, bnbClf_ypred, average = 'weighted')\n",
    "accuracy_bnbClf = accuracy_score(y_test, bnbClf_ypred)\n",
    "print (\"F1-score of Bernoulli Naive Bayes: \", f1_bnbClf*100)\n",
    "print (\"Accuracy of Bernoulli Naive Bayes: \", accuracy_bnbClf*100)\n",
    "\n",
    "\n",
    "print (\"\\n2. TFIDF Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "topic_num = data['topic_num']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, topic_num, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "bnbTfidfClf = BernoulliNB()\n",
    "bnbTfidfClf.fit(X_train, y_train)\n",
    "bnbTfidfClf_ypred = bnbTfidfClf.predict(X_test)\n",
    "f1_bnbTfidfClf = f1_score(y_test, bnbTfidfClf_ypred, average='weighted')\n",
    "accuracy_bnbTfidfClf = accuracy_score(y_test, bnbTfidfClf_ypred)\n",
    "print (\"F1-score of Bernoulli Naive Bayes with TFIDF: \", f1_bnbTfidfClf*100)\n",
    "print (\"Accuracy of Bernoulli Naive Bayes with TFIDF: \", accuracy_bnbTfidfClf*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Model - Logistic Regression\n",
    "1. Count Vectorizer\n",
    "2. TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Count Vectorizer\n",
      "F1-score of Logistic Regression:  97.10929609617548\n",
      "Accuracy of Logistic Regression:  97.14908603052154\n",
      "\n",
      "2. TFIDF Vectorizer\n",
      "F1-score of Logistic Regression with TFIDF:  97.04153421164125\n",
      "Accuracy of Logistic Regression with TFIDF:  97.06523561965453\n"
     ]
    }
   ],
   "source": [
    "print (\"1. Count Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "topic_num = data['topic_num']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, topic_num, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "logRegClf = LogisticRegression()\n",
    "logRegClf.fit(X_train, y_train)\n",
    "logRegClf_ypred = logRegClf.predict(X_test)\n",
    "f1_logRegClf = f1_score(y_test, logRegClf_ypred, average = 'weighted')\n",
    "accuracy_logRegClf = accuracy_score(y_test, logRegClf_ypred)\n",
    "print (\"F1-score of Logistic Regression: \", f1_logRegClf*100)\n",
    "print (\"Accuracy of Logistic Regression: \", accuracy_logRegClf*100)\n",
    "\n",
    "\n",
    "print (\"\\n2. TFIDF Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "topic_num = data['topic_num']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, topic_num, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "logRegTfidfClf = LogisticRegression()\n",
    "logRegTfidfClf.fit(X_train, y_train)\n",
    "logRegTfidfClf_ypred = logRegTfidfClf.predict(X_test)\n",
    "f1_logRegTfidfClf = f1_score(y_test, logRegTfidfClf_ypred, average='weighted')\n",
    "accuracy_logRegTfidfClf = accuracy_score(y_test, logRegTfidfClf_ypred)\n",
    "print (\"F1-score of Logistic Regression with TFIDF: \", f1_logRegTfidfClf*100)\n",
    "print (\"Accuracy of Logistic Regression with TFIDF: \", accuracy_logRegTfidfClf*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Model - Support Vector Machine\n",
    "1. Count Vectorizer\n",
    "2. TFIDF Vectorizer\n",
    "3. Count Vectorizer with Tuning\n",
    "4. TFIDF Vectorizer with Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Count Vectorizer\n",
      "F1-score of SVM:  71.75174864018979\n",
      "Accuracy of SVM:  74.32500419252054\n",
      "\n",
      "2. TFIDF Vectorizer\n",
      "F1-score of SVM with TFIDF:  97.04153421164125\n",
      "Accuracy of SVM with TFIDF:  97.06523561965453\n",
      "\n",
      "3. Count Vectorizer with Tuning\n",
      "F1-score of SVM with Tuning:  98.79102631018193\n",
      "Accuracy of SVM with Tuning:  98.792554083515\n",
      "{'C': 3, 'degree': 1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "4. TFIDF Vectorizer with Tuning\n",
      "F1-score of SVM with TFIDF with Tuning:  98.87544027095521\n",
      "Accuracy of SVM with TFIDF with Tuning:  98.87640449438202\n",
      "{'C': 3, 'degree': 1, 'gamma': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print (\"1. Count Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "topic_num = data['topic_num']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, topic_num, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "svmClf = SVC()\n",
    "svmClf.fit(X_train, y_train)\n",
    "svmClf_ypred = svmClf.predict(X_test)\n",
    "f1_svmClf = f1_score(y_test, svmClf_ypred, average = 'weighted')\n",
    "accuracy_svmClf = accuracy_score(y_test, svmClf_ypred)\n",
    "print (\"F1-score of SVM: \", f1_svmClf*100)\n",
    "print (\"Accuracy of SVM: \", accuracy_svmClf*100)\n",
    "\n",
    "\n",
    "print (\"\\n2. TFIDF Vectorizer\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "topic_num = data['topic_num']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, topic_num, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "svmTfidfClf = LogisticRegression()\n",
    "svmTfidfClf.fit(X_train, y_train)\n",
    "svmTfidfClf_ypred = svmTfidfClf.predict(X_test)\n",
    "f1_svmTfidfClf = f1_score(y_test, svmTfidfClf_ypred, average='weighted')\n",
    "accuracy_svmTfidfClf = accuracy_score(y_test, svmTfidfClf_ypred)\n",
    "print (\"F1-score of SVM with TFIDF: \", f1_svmTfidfClf*100)\n",
    "print (\"Accuracy of SVM with TFIDF: \", accuracy_svmTfidfClf*100)\n",
    "\n",
    "print (\"\\n3. Count Vectorizer with Tuning\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "topic_num = data['topic_num']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, topic_num, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = False, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "# parameters = {'C':[1,2,3,4,5,6,7,8,14], 'gamma':[0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2,3,4,5]}\n",
    "parameters = {'C':[1,2,3], 'gamma':[0.1, 0.01], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2]}\n",
    "\n",
    "svmClfTuned = GridSearchCV(estimator=SVC(), param_grid=parameters)\n",
    "svmClfTuned.fit(X_train, y_train)\n",
    "svmClfTuned_ypred = svmClfTuned.predict(X_test)\n",
    "f1_svmClfTuned = f1_score(y_test, svmClfTuned_ypred, average = 'weighted')\n",
    "accuracy_svmClfTuned = accuracy_score(y_test, svmClfTuned_ypred)\n",
    "print (\"F1-score of SVM with Tuning: \", f1_svmClfTuned*100)\n",
    "print (\"Accuracy of SVM with Tuning: \", accuracy_svmClfTuned*100)\n",
    "print(svmClfTuned.best_params_)\n",
    "\n",
    "\n",
    "print (\"\\n4. TFIDF Vectorizer with Tuning\")\n",
    "\n",
    "reviews = all_data_cleaned\n",
    "topic_num = data['topic_num']\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, topic_num, test_size=0.25, random_state=42)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(use_idf = True, min_df = 4, max_df=0.85)\n",
    "X_train = tfidfVectorizer.fit_transform(X_train)\n",
    "X_test = tfidfVectorizer.transform(X_test)\n",
    "\n",
    "# parameters = {'C':[1,2,3,4,5,6,7,8,14], 'gamma':[0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2,3,4,5]}\n",
    "parameters = {'C':[1,2,3], 'gamma':[0.1, 0.01], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2]}\n",
    "\n",
    "svmTfidfClfTuned = GridSearchCV(estimator=SVC(), param_grid=parameters)\n",
    "svmTfidfClfTuned.fit(X_train, y_train)\n",
    "svmTfidfClfTuned_ypred = svmTfidfClfTuned.predict(X_test)\n",
    "f1_svmTfidfClfTuned = f1_score(y_test, svmTfidfClfTuned_ypred, average='weighted')\n",
    "accuracy_svmTfidfClfTuned = accuracy_score(y_test, svmTfidfClfTuned_ypred)\n",
    "print (\"F1-score of SVM with TFIDF with Tuning: \", f1_svmTfidfClfTuned*100)\n",
    "print (\"Accuracy of SVM with TFIDF with Tuning: \", accuracy_svmTfidfClfTuned*100)\n",
    "print (svmTfidfClfTuned.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Multinomial Naive Bayes:  92.55332206254671\n",
      "Accuracy of Multinomial Naive Bayes:  92.67147409022304\n",
      "F1-score of Multinomial Naive Bayes with TFIDF:  92.8543552552533\n",
      "Accuracy of Multinomial Naive Bayes with TFIDF:  92.93979540499748\n",
      "\n",
      "\n",
      "F1-score of Bernoulli Naive Bayes:  90.91530178040284\n",
      "Accuracy of Bernoulli Naive Bayes:  91.0950863659232\n",
      "F1-score of Bernoulli Naive Bayes with TFIDF:  90.91530178040284\n",
      "Accuracy of Bernoulli Naive Bayes with TFIDF:  91.0950863659232\n",
      "\n",
      "\n",
      "F1-score of Logistic Regression:  97.10929609617548\n",
      "Accuracy of Logistic Regression:  97.14908603052154\n",
      "F1-score of Logistic Regression with TFIDF:  97.04153421164125\n",
      "Accuracy of Logistic Regression with TFIDF:  97.06523561965453\n",
      "\n",
      "\n",
      "F1-score of SVM:  71.75174864018979\n",
      "Accuracy of SVM:  74.32500419252054\n",
      "F1-score of SVM with TFIDF:  97.04153421164125\n",
      "Accuracy of SVM with TFIDF:  97.06523561965453\n",
      "\n",
      "\n",
      "F1-score of SVM with Tuning:  98.79102631018193\n",
      "Accuracy of SVM with Tuning:  98.792554083515\n",
      "{'C': 3, 'degree': 1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "F1-score of SVM with TFIDF with Tuning:  98.87544027095521\n",
      "Accuracy of SVM with TFIDF with Tuning:  98.87640449438202\n",
      "{'C': 3, 'degree': 1, 'gamma': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print (\"F1-score of Multinomial Naive Bayes: \", f1_mnbClf*100)\n",
    "print (\"Accuracy of Multinomial Naive Bayes: \", accuracy_mnbClf*100)\n",
    "print (\"F1-score of Multinomial Naive Bayes with TFIDF: \", f1_mnbTfidfClf*100)\n",
    "print (\"Accuracy of Multinomial Naive Bayes with TFIDF: \", accuracy_mnbTfidfClf*100)\n",
    "print (\"\\n\")\n",
    "print (\"F1-score of Bernoulli Naive Bayes: \", f1_bnbClf*100)\n",
    "print (\"Accuracy of Bernoulli Naive Bayes: \", accuracy_bnbClf*100)\n",
    "print (\"F1-score of Bernoulli Naive Bayes with TFIDF: \", f1_bnbTfidfClf*100)\n",
    "print (\"Accuracy of Bernoulli Naive Bayes with TFIDF: \", accuracy_bnbTfidfClf*100)\n",
    "print (\"\\n\")\n",
    "print (\"F1-score of Logistic Regression: \", f1_logRegClf*100)\n",
    "print (\"Accuracy of Logistic Regression: \", accuracy_logRegClf*100)\n",
    "print (\"F1-score of Logistic Regression with TFIDF: \", f1_logRegTfidfClf*100)\n",
    "print (\"Accuracy of Logistic Regression with TFIDF: \", accuracy_logRegTfidfClf*100)\n",
    "print (\"\\n\")\n",
    "print (\"F1-score of SVM: \", f1_svmClf*100)\n",
    "print (\"Accuracy of SVM: \", accuracy_svmClf*100)\n",
    "print (\"F1-score of SVM with TFIDF: \", f1_svmTfidfClf*100)\n",
    "print (\"Accuracy of SVM with TFIDF: \", accuracy_svmTfidfClf*100)\n",
    "print (\"\\n\")\n",
    "print (\"F1-score of SVM with Tuning: \", f1_svmClfTuned*100)\n",
    "print (\"Accuracy of SVM with Tuning: \", accuracy_svmClfTuned*100)\n",
    "print(svmClfTuned.best_params_)\n",
    "print (\"\\n\")\n",
    "print (\"F1-score of SVM with TFIDF with Tuning: \", f1_svmTfidfClfTuned*100)\n",
    "print (\"Accuracy of SVM with TFIDF with Tuning: \", accuracy_svmTfidfClfTuned*100)\n",
    "print (svmTfidfClfTuned.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual check againt the classifier classification \n",
    "The classification done by the best model (tuned SVM with TFIDF) was saved to a csv file to do a manual check against the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse matrix length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-631e15d3f388>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtesting_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtesting_actual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msvmTfidfClfTuned_ypred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtesting_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'delivery'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;31m# non-zeros is more important.  For now, raise an exception!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         raise TypeError(\"sparse matrix length is ambiguous; use getnnz()\"\n\u001b[0m\u001b[0;32m    296\u001b[0m                         \" or shape[0]\")\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "testing_predictions = []\n",
    "testing_actual = []\n",
    "for i in range(len((X_test))):\n",
    "    if svmTfidfClfTuned_ypred[i] == 0:\n",
    "        testing_predictions.append('delivery')\n",
    "    elif svmTfidfClfTuned_ypred[i] == 1:\n",
    "        testing_predictions.append('service')\n",
    "    elif svmTfidfClfTuned_ypred[i] == 2:\n",
    "        testing_predictions.append('price')\n",
    "    elif svmTfidfClfTuned_ypred[i] == 3:\n",
    "        testing_predictions.append('quality')\n",
    "    else:\n",
    "        testing_predictions.append('no_topic')\n",
    "        \n",
    "for i in range(len((X_test))):\n",
    "    if  list(X_test)[i]== 0:\n",
    "        testing_actual.append('delivery')\n",
    "    elif list(X_test)[i] == 1:\n",
    "        testing_actual.append('service')\n",
    "    elif list(X_test)[i] == 2:\n",
    "        testing_actual.append('price')\n",
    "    elif list(X_test)[i] == 3:\n",
    "        testing_actual.append('quality')\n",
    "    else:\n",
    "        testing_actual.append('no_topic')\n",
    "        \n",
    "check_df = pd.DataFrame({'actual label': list(y_test), 'prediction': testing_prediction, 'abstract':list(X_test)})\n",
    "# check_df.to_csv('Data/check_df.csv')\n",
    "check_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pickle and save the classifier and vectorizer to the pickle\n",
    "The pickle can be use when new reviews are inserted into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidfVectorizer, open(\"../topic_vectorizer.pickle\", \"wb\"))\n",
    "pickle.dump(svmTfidfClfTuned, open(\"../topic_classifier.pickle\", 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
